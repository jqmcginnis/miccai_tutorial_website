---
layout: project
urltitle:  "MICCAI Tutorial on Implicit Neural Representations for Medical Imaging"
title: "MICCAI Tutorial on Implicit Neural Representations for Medical Imaging"
categories: miccai2024, tutorial, computer vision, machine learning, implicit neural representations, medical imaging, neural fields, nerfs
permalink: /
favicon: /static/img/eccv-final.png
bibtex: true
paper: true
acknowledgements: ""
---

<br>
<div class="row">
  <div class="col-xs-12">
  <center><h2>MICCAI 2024 Tutorial on</h2></center>
    <center><h1>Implicit Neural Representations for Medical Imaging>
        <center>Sunday 06 October, 08:00 am - 12:30 pm (GMT+1)<font color="#76b900"></font></center> 
  </div>
</div>
<br>

Discover the latest advancements in machine learning tailored for medical imaging with our upcoming tutorial on Implicit Neural Representations (INR). INRs have shown promise in various computer vision tasks like 3D scene reconstruction, image denoising, superresolution, and compression. In recent years, the medical imaging community has shown increasing interest in the potential of INRs for personalized solutions, spanning tasks like registration, reconstruction, super-resolution, shape modeling, and segmentation. As this interest grows, we’re excited to announce the launch of the inaugural MICCAI tutorial on INRs for medical imaging. This tutorial will offer a comprehensive overview of INR research progress, highlighting key applications in medical imaging and exploring future directions through engaging lectures and practical demonstrations. Join us and learn from experts in the field who are known for their contributions to both computer vision and medical research. Whether you’re an experienced researcher or new to medical imaging, this tutorial promises valuable insights into leveraging INRs for advancements in healthcare.

<br id="speakers">
<br>

<div class="row">
  <div class="col-xs-12">
    <h2>Speakers</h2>
  </div>
</div>
<div class="row">
  <div class="col-xs-12">

    <div class="col-xs-2" id="sifei">
      <a href="https://jelmerwolterink.nl/">
        <img class="people-pic" src="{{ "/static/img/people/jw.jpeg" | prepend:site.baseurl }}">
      </a>
      <div class="people-name">
        <a href="https://jelmerwolterink.nl/">Jelmer Wolterink</a>
        <h6>University of Twente</h6>
      </div>
    </div><div class="col-xs-2" id="sifei">
  <a href="https://jelmerwolterink.nl/">
    <img class="people-pic" src="{{ "/static/img/people/jw.jpeg" | prepend:site.baseurl }}">
  </a>
  <div class="people-name">
    <a href="https://jelmerwolterink.nl/">Jelmer Wolterink</a>
    <h6>University of Twente</h6>
  </div>
</div>
<div class="row">
  <div class="col-xs-12">

    <div class="col-xs-2" id="jonathan">
      <a href="https://jonathan-schwarz.github.io/">
        <img class="people-pic" src="{{ "/static/img/people/jonathan.jpeg" | prepend:site.baseurl }}">
      </a>
      <div class="people-name">
        <a href="https://jonathan-schwarz.github.io/">Jonathan Richard Schwarz</a>
        <h6>Harvard University, Safe Sign Technologies</h6>
      </div>
    </div>

    <div class="col-xs-2" id="jonathan">
      <a href="https://jonathan-schwarz.github.io/">
        <img class="people-pic" src="{{ "/static/img/people/jonathan.jpeg" | prepend:site.baseurl }}">
      </a>
      <div class="people-name">
        <a href="https://jonathan-schwarz.github.io/">Jonathan Richard Schwarz</a>
        <h6>Harvard University, Safe Sign Technologies</h6>
      </div>
    </div>

  </div>
</div>



<br id="talks">

<div class="row">
  <div class="col-xs-12">
     <h2>Talks</h2>
     <table class="table schedule" style="border:none !important;">
      <thead class="thead-light">
        <tr>
        <th>Title</th>
        <th>Speaker</th>
        <th></th>
        <th></th>
        <th>Live Session</th>
        </tr>
      </thead>
      <tbody>

        <tr>
            <td>Introduction</td>
            <td><a href="https://research.nvidia.com/person/shalini-gupta">Shalini De Mello</a></td>
            <td><a target="_blank" href="https://youtu.be/lHsLUYk80z4">Video</a></td>
            <td><a target="_blank" href="https://drive.google.com/file/d/1j-O0az3BEeHuTPWmRurSDdsQxe6e3V74/view?usp=sharing">PDF</a></td>
            <td><strike>22 Aug, 5:30 pm (PDT)</strike></td>
        </tr>
        <tr>
            <td><b>Self-supervised Learning</b></td>
            <td> </td>
            <td> </td>
            <td> </td>
            <td> </td>
        </tr>
        <tr>
            <td>Self-Supervised Part and Viewpoint Discovery from Image Collections</td>
            <td><a href="https://varunjampani.github.io/">Varun Jampani</a></td>
            <td><a target="_blank" href="https://youtu.be/5kzU6NkvGX4">Video</a></td>
            <td><a target="_blank" href="https://drive.google.com/file/d/1eSy0IbLB9y5By7Umu16zhI8z1UDZJtoe/view?usp=sharing">PDF</a></td>
            <td><strike>22 Aug, 5:30 - 6:00 pm (PDT)</strike></td>
        </tr>
        <tr>
            <td>Learning Visual Correspondences across Instances and Video Frames</td>
            <td><a href="https://www.sifeiliu.net/">Sifei Liu</a></td>
            <td><a target="_blank" href="https://youtu.be/_Sug0ICzKlk">Video</a></td>
            <td><a target="_blank" href="https://drive.google.com/file/d/13tuczzIikN5KCrSvHmyhcfs9d1XuJii8/view?usp=sharing">PDF</a></td>
            <td><strike>22 Aug, 6:00 - 6:30 pm (PDT)</strike></td>
        </tr>
        <tr>
            <td><b>Imperfect Labels</b></td>
            <td> </td>
            <td> </td>
            <td> </td>
            <td> </td>
        </tr>
        <tr>
            <td>Limitless Labels in a Labelless World: Weak Supervision with Noisy Labels</td>
            <td><a href="http://latentspace.cc/arash_vahdat/">Arash Vahdat</a></td>
            <td><a target="_blank" href="https://youtu.be/UtxQkIoei0o">Video</a></td>
            <td><a target="_blank" href="https://drive.google.com/file/d/1MIlAhzEpJecSXuzmQjSirAVQcX4qjGp6/view?usp=sharing">PDF</a></td>
            <td><strike>22 Aug, 6:30 - 7:00 pm (PDT)</strike></td>
        </tr>
        <tr>
            <td>Learning with Imperfect Labels and Visual Data</td>
            <td><a href="https://chrisding.github.io/index.htm">Zhiding Yu</a></td>
            <td><a target="_blank" href="https://youtu.be/6bDP7YfiwW4">Video</a></td>
            <td><a target="_blank" href="https://drive.google.com/file/d/1MyNXLhtFo3-ytKMxEGdm3XFsxejWKxbr/view?usp=sharing">PDF</a></td>
            <td><strike>23 Aug, 6:30 - 7:00 am (PDT)</strike></td>
        </tr>
        <tr>
            <td><b>Inverting Neural Networks</b></td>
            <td> </td>
            <td> </td>
            <td> </td>
            <td> </td>
        </tr>
        <tr>
          <td>Inverting Neural Networks for Data-free Knowledge Transfer</td>
          <td><a href="https://research.nvidia.com/person/pavlo-molchanov">Pavlo Molchanov</a></td>
          <td><a target="_blank" href="https://youtu.be/ddEtea4ntEU">Video</a></td>
          <td><a target="_blank" href="https://drive.google.com/file/d/1oMBMzArh5_qcRof6BLfG09Tt1VxBf2y8/view?usp=sharing">PDF</a></td>
          <td><strike>23 Aug, 7:00 - 7:30 am (PDT)</strike></td>
        </tr>
        <tr>
          <td>Learning Efficiently with Biologically Inspired Feedback</td>
          <td><a href="https://yjhuangcd.github.io/">Yujia Huang</a></td>
          <td><a target="_blank" href="https://youtu.be/8N9AF8V52-E">Video</a></td>
          <td><a target="_blank" href="https://drive.google.com/file/d/1tngSUhyBVHyoYjVP0YwIwNZOB0XaWRQa/view?usp=sharing">PDF</a></td>
          <td><strike>23 Aug, 7:30 - 8:00 am (PDT)</strike></td>
        </tr>
      </tbody>
    </table>
  </div>
</div>

<br id="organizers">

<div class="row">
  <div class="col-xs-12">
    <h2>Organizers</h2>
  </div>
</div>

<div class="row speaker" id="mcginnis">
  <div class="col-sm-3 speaker-pic">
    <a href="https://aim-lab.io/author/julian-mcginnis/">
      <img class="people-pic" src="{{ "/static/img/people/julian1.jpeg" | prepend:site.baseurl }}">
    </a>
    <div class="people-name">
      <a href="https://aim-lab.io/author/julian-mcginnis/">Julian McGinnis</a> <a href="https://twitter.com/jqmcginnis"><img src="{{ "/static/img/Twitter_Social_Icon_Rounded_Square_Color.png" | prepend:site.baseurl }}"></a>
      <h6>Technical University of Munich</h6>
    </div>
  </div>
  <div class="col-md-9">
    <b>Biography</b>
    <p class="speaker-bio">
    Julian McGinnis is a PhD student at the Department of Neurology and the Institute of Artificial Intelligence in Medicine at the Technical University of Munich (TUM). His research is centered on the intersection of medicine, neuroscience, and machine learning, specifically focusing on Multiple Sclerosis (MS) and the integrated analysis of the brain and spinal cord. His interests revolve around implicit neural representations and compact latent representations for various downstream tasks. These tasks include generative modeling, image reconstruction, and lesion segmentation. 
    </p>
  </div>
</div>

<div class="row speaker" id="suprosanna">
  <div class="col-sm-3 speaker-pic">
    <a href="https://www.uzh.ch/cmsssl/en.html">
      <img class="people-pic" src="{{ "/static/img/people/suprosanna.jpeg" | prepend:site.baseurl }}">
    </a>
    <div class="people-name">
      <a href="https://www.uzh.ch/cmsssl/en.html">Suprosanna Shit</a>
      <h6>University of Zurich</h6>
    </div>
  </div>
  <div class="col-md-9">
    <b>Biography</b>
    <p class="speaker-bio">
    Suprosanna Shit is a post-doc at the University of Zurich. His current research focuses on applications of INRs and patient-specific solutions and has been published at MICCAI’23.
    </p>
  </div>
</div>

<div class="row speaker" id="sideri">
  <div class="col-sm-3 speaker-pic">
    <a href="https://www.tum.de/en">
      <img class="people-pic" src="{{ "/static/img/people/sideri.jpeg" | prepend:site.baseurl }}">
    </a>
    <div class="people-name">
      <a href="https://www.tum.de/en">Vasiliki Sideri-Lampretsa</a>
      <h6>Technical University of Munich</h6>
    </div>
  </div>
  <div class="col-md-9">
    <b>Biography</b>
    <p class="speaker-bio">
    Vasiliki Sideri-Lampretsa is a Ph.D. student at TUM. She has prior experience as a tutorial speaker at Learn2Reg at MICCAI’23. Her current interest revolves around INRs for registration.
    </p>
  </div>
</div>

<div class="row speaker" id="spieker">
  <div class="col-sm-3 speaker-pic">
    <a href="https://www.helmholtz-munich.de/en/index.html">
      <img class="people-pic" src="{{ "/static/img/people/spieker.jpeg" | prepend:site.baseurl }}">
    </a>
    <div class="people-name">
      <a href="https://www.helmholtz-munich.de/en/index.html">Veronika Spieker</a>
      <h6>Helmholtz Munich and Technical University of Munich</h6>
    </div>
  </div>
  <div class="col-md-9">
    <b>Biography</b>
    <p class="speaker-bio">
    Veronika Spieker is a Ph.D. student at Helmholtz Munich and TUM. Her current research focuses on INRs for k-space reconstruction.
    </p>
  </div>
</div>

<div class="row speaker" id="nil">
  <div class="col-sm-3 speaker-pic">
    <a href="https://www.tum.de/en">
      <img class="people-pic" src="{{ "/static/img/people/nil.jpeg" | prepend:site.baseurl }}">
    </a>
    <div class="people-name">
      <a href="https://www.tum.de/en">Nil Stolt-Anso</a>
      <h6>Technical University of Munich</h6>
    </div>
  </div>
  <div class="col-md-9">
    <b>Biography</b>
    <p class="speaker-bio">
    Nil Stolt-Anso is a PhD student at TUM. His current research focuses on the application of Neural Implicit Segmentation Functions (NISF) for cardiac imaging and other applications.
    </p>
  </div>
</div> 

<div class="row speaker" id="maik">
  <div class="col-sm-3 speaker-pic">
    <a href="https://www.tum.de/en">
      <img class="people-pic" src="{{ "/static/img/people/maik.jpeg" | prepend:site.baseurl }}">
    </a>
    <div class="people-name">
      <a href="https://www.tum.de/en">Maik Dannecker</a>
      <h6>Technical University of Munich</h6>
    </div>
  </div>
  <div class="col-md-9">
    <b>Biography</b>
    <p class="speaker-bio">
    Maik Dannecker is a PhD student at TUM. His current research focuses on the application of INRs for fetal image reconstruction, and is submitted to MICCAI’24.
    </p>
  </div>
</div>

